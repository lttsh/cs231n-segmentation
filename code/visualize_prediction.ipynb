{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from train import Trainer\n",
    "from generator import *\n",
    "from discriminator import GAN\n",
    "from dataset import CocoStuffDataSet\n",
    "import os, argparse, datetime, json\n",
    "\n",
    "from utils import *\n",
    "NUM_CLASSES = 11\n",
    "SAVE_DIR = \"../checkpoints\" # Assuming this is launched from code/ subfolder.\n",
    "# experiment_name = 'gan_animal'\n",
    "experiment_name = 'animal-batchnorm-50-nobnend'\n",
    "# experiment_name = 'animal-bn-50-gan-55'\n",
    "use_bn = True\n",
    "experiment_dir = os.path.join(SAVE_DIR, experiment_name)\n",
    "batch_size = 64\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT, WIDTH = 128, 128\n",
    "# HEIGHT = WIDTH = 256\n",
    "val_loader = DataLoader(CocoStuffDataSet(mode='val', supercategories=['animal'], height=HEIGHT, width=WIDTH),\n",
    "                            batch_size, shuffle=False)\n",
    "train_loader = DataLoader(CocoStuffDataSet(mode='train', supercategories=['animal'], height=HEIGHT, width=WIDTH),\n",
    "                            batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SegNet16(NUM_CLASSES, use_bn=use_bn)\n",
    "\n",
    "image_shape = (3, HEIGHT, WIDTH)\n",
    "segmentation_shape = (NUM_CLASSES, HEIGHT, WIDTH)\n",
    "# discriminator = GAN(NUM_CLASSES, segmentation_shape, image_shape)\n",
    "discriminator = None\n",
    "trainer = Trainer(generator, discriminator, train_loader, val_loader, \\\n",
    "                experiment_dir=experiment_dir, resume=True, load_iter=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mask(trainer, loader, number):\n",
    "    total = 0\n",
    "    to_return = []\n",
    "    for data, mask_gt, gt_visual in loader:\n",
    "        if total < number: \n",
    "            data = data.to(trainer.device)\n",
    "            batch_size = data.size()[0]\n",
    "            mask_pred = convert_to_mask(trainer._gen(data))\n",
    "            for i in range(len(data)):\n",
    "                img = data[i].detach().cpu().numpy()\n",
    "                gt_mask = gt_visual[i].detach().cpu().numpy()\n",
    "                pred_mask = np.argmax(mask_pred[i].detach().cpu().numpy(), axis=0)\n",
    "                \n",
    "                to_return.append((img, gt_mask, pred_mask))\n",
    "                display_image = np.transpose(img, (1, 2, 0))\n",
    "                plt.figure()\n",
    "\n",
    "                plt.subplot(131)\n",
    "                plt.imshow(display_image)\n",
    "                plt.axis('off')\n",
    "                plt.title('original image')\n",
    "\n",
    "                cmap = discrete_cmap(NUM_CLASSES, 'Paired')\n",
    "                norm = colors.NoNorm(vmin=0, vmax=NUM_CLASSES)\n",
    "\n",
    "                plt.subplot(132)\n",
    "                plt.imshow(display_image)\n",
    "                plt.imshow(gt_mask, alpha=0.8, cmap=cmap, norm=norm)\n",
    "                plt.axis('off')\n",
    "                plt.title('real mask')\n",
    "\n",
    "                plt.subplot(133)\n",
    "                plt.imshow(display_image)\n",
    "                plt.imshow(pred_mask, alpha=0.8, cmap=cmap, norm=norm)\n",
    "                plt.axis('off')\n",
    "                plt.title('predicted mask')\n",
    "                plt.show()\n",
    "                \n",
    "                ### Now save image and background masks for style transfer\n",
    "                idx = i + total\n",
    "                print (\"Image {}\".format(idx))\n",
    "                savedir = os.path.join('./saved_images_and_masks', str(idx))\n",
    "                if not os.path.exists(savedir):\n",
    "                    os.makedirs(savedir)\n",
    "                gt_background = np.where(gt_mask == 10., 1, 0)\n",
    "                pred_background = np.where(pred_mask == 10., 1, 0)\n",
    "                torch.save(torch.from_numpy(img), os.path.join(savedir, 'img.pk'))\n",
    "                torch.save(torch.from_numpy(gt_background), os.path.join(savedir, 'gt_mask.pk')) # only care about background class\n",
    "                torch.save(torch.from_numpy(pred_background), os.path.join(savedir, 'gen_mask.pk'))  # only care about background class\n",
    "                plt.imshow(gt_background)\n",
    "                plt.show()\n",
    "                plt.imshow(pred_background)\n",
    "                plt.show()\n",
    "            total += batch_size\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_mask(trainer, train_loader, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = visualize_mask(trainer, val_loader, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pixel_acc, val_mIOU, per_class_accuracy = trainer.evaluate(val_loader, 0, ignore_background=True, save_mask=False)\n",
    "\n",
    "print (\"Pixel accuracy {}\".format(val_pixel_acc))\n",
    "print (\"Val mIOU {}\".format(val_mIOU))\n",
    "print (\"per_class_accuracy {}\".format(per_class_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFUSION MATRIX ##\n",
    "\n",
    "confusion_matrix = trainer.get_confusion_matrix(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_loader.dataset\n",
    "coco = dataset.coco\n",
    "all_cats_ids = coco.getCatIds()\n",
    "cats = coco.loadCats(all_cats_ids)\n",
    "nms=[cat['name'] for cat in cats]\n",
    "\n",
    "animal_cat_names = [nms[all_cats_ids.index(i)] for i in val_loader.dataset.catIds] + ['background']\n",
    "print (animal_cat_names)\n",
    "visualize_conf(confusion_matrix, animal_cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
